const fetch = (...args) => import('node-fetch').then(({default: fetch}) => fetch(...args))
require('dotenv').config({ path: '.env.local' })

async function checkOpenAIModels() {
  try {
    console.log('ğŸ” OpenAIåˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ç¢ºèªé–‹å§‹...\n')

    // 1. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—
    console.log('ğŸ“‹ 1. åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§:')
    
    const response = await fetch('https://api.openai.com/v1/models', {
      method: 'GET',
      headers: {
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
        'Content-Type': 'application/json',
      }
    })

    if (response.ok) {
      const data = await response.json()
      const models = data.data || []
      
      console.log(`  ğŸ“Š ç·ãƒ¢ãƒ‡ãƒ«æ•°: ${models.length}å€‹`)
      console.log('  ğŸ“‹ ãƒãƒ£ãƒƒãƒˆç”¨ãƒ¢ãƒ‡ãƒ«:')
      
      // GPT-4ç³»ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã™
      const gpt4Models = models.filter(model => 
        model.id.includes('gpt-4') || model.id.includes('gpt-3.5')
      )
      
      gpt4Models.forEach(model => {
        console.log(`    - ${model.id} (${model.owned_by})`)
      })
      
      // æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®š
      console.log('\n  ğŸ’¡ æ¨å¥¨ãƒ¢ãƒ‡ãƒ«:')
      const recommendedModels = [
        'gpt-4o',
        'gpt-4o-mini',
        'gpt-4-turbo',
        'gpt-3.5-turbo'
      ]
      
      recommendedModels.forEach(modelId => {
        const model = models.find(m => m.id === modelId)
        if (model) {
          console.log(`    âœ… ${modelId}: åˆ©ç”¨å¯èƒ½`)
        } else {
          console.log(`    âŒ ${modelId}: åˆ©ç”¨ä¸å¯`)
        }
      })
      
    } else {
      const errorText = await response.text()
      console.log(`  âŒ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—å¤±æ•—: ${errorText}`)
    }

    // 2. æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    console.log('\nğŸ“‹ 2. æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã§ã®ãƒ†ã‚¹ãƒˆ:')
    
    const testModels = ['gpt-4o-mini', 'gpt-3.5-turbo']
    
    for (const modelId of testModels) {
      console.log(`\n  ğŸ§ª ${modelId}ã§ã®ãƒ†ã‚¹ãƒˆ:`)
      
      try {
        const testResponse = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: modelId,
            messages: [
              {
                role: 'system',
                content: 'ã‚ãªãŸã¯å»ºè¨­æ¥­å‘ã‘åŸä¾¡ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚'
              },
              {
                role: 'user',
                content: 'ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§ã™ã€‚'
              }
            ],
            max_tokens: 100,
            temperature: 0.7,
          }),
        })

        if (testResponse.ok) {
          const data = await testResponse.json()
          const response = data.choices[0]?.message?.content
          console.log(`    âœ… ${modelId}: æˆåŠŸ`)
          console.log(`    ğŸ“ ãƒ¬ã‚¹ãƒãƒ³ã‚¹: ${response?.substring(0, 50)}...`)
        } else {
          const errorText = await testResponse.text()
          console.log(`    âŒ ${modelId}: å¤±æ•— - ${errorText}`)
        }
      } catch (error) {
        console.log(`    âŒ ${modelId}: ã‚¨ãƒ©ãƒ¼ - ${error.message}`)
      }
    }

    console.log('\nâœ… ãƒ¢ãƒ‡ãƒ«ç¢ºèªå®Œäº†ï¼')

  } catch (error) {
    console.error('âŒ ã‚¨ãƒ©ãƒ¼:', error)
  }
}

checkOpenAIModels()
